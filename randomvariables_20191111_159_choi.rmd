---
title: "R Notebook"
output: html_notebook
---

# Chapter 14. Random Variables

## 14.1 Random Variables
:실행할 때마다 다른 값이 나오는 변수

Here `X` is a random variable: every time we select a new bead the outcome changes randomly. See below:
```{r}
beads <- rep( c("red", "blue"), times = c(2,3))
X <- ifelse(sample(beads, 1) == "blue", 1, 0)

ifelse(sample(beads, 1) == "blue", 1, 0)
ifelse(sample(beads, 1) == "blue", 1, 0)
ifelse(sample(beads, 1) == "blue", 1, 0)
```


## 14.2 Sampling models

[urn:individuals assigned] ->(draw)-> Random

Because we know the proportions of 1s and -1s, we can generate the draws with one line of code, without defining `color`:
```{r}
n <- 1000
X <- sample(c(-1,1), n, replace = TRUE, prob=c(9/19, 10/19))
```
We call this a **sampling model** since we are modeling the random behavior of roulette with the sampling of draws from an urn. The total winnings **S** is simply the sum of these 1,000 independent draws:
```{r}
X <- sample(c(-1,1), n, replace = TRUE, prob=c(9/19, 10/19))
S <- sum(X)
S
```

## 14.3 The probability distribution of random variable
S <- random variable
F(a) = Pr(S<=a) <- random variable's distribution function
mean(S) <- expected value
sd(S) <- standard error

binominal distribution: 이항분포(일정한 확률 p를 가진 독립시행을 n번 반복했을때의 확률분포)
**B(n,p), n번 중 r번 실행될 확률: P(X=r)=nCr*p^r*(1-p)^(n-r)**
**이항분포는 discrete하다!!**

`pbinom` : 이항분포에 대하여 p(x<=a) 확률 계산
pbinom(a, size=n, prob=p)
#> p(x<=a)

`dbinom` : 이항분포에 대하여 P(x)의 값
dbinom(x, size, prob)



S is random variable.
```{r}
n <- 1000
B <- 10000
roulette_winnings <- function(n){
  X <- sample(c(-1,1), n, replace = TRUE, prob=c(9/19, 10/19))
  sum(X)
}
S <- replicate(B, roulette_winnings(n))

```

Now we can ask the following: in our simulations, how often did we get sums less than or equal to a?
```{r}
mean(S <= a)
```
This will be a very good approximation of F(a) and we can easily answer the casino’s question: how likely is it that we will lose money? We can see it is quite low:
```{r}
mean(S<0)
```


Specifically, in our example above, we can show that (S+n)/2 follow a binomial distribution.

We can use the function `dbinom` and `pbinom` to compute the probabilities exactly. For example, to compute Pr(S<0), we note that:
Pr(S<0) = Pr((S+n)/2 < (0+n)/2)
and we can use the `pbinom` to compute Pr(S<=0)
```{r}
n <- 1000
pbinom(n/2, size = n, prob = 10/19)
```

Because this is a discete probability function, to get Pr(S<0) rather than Pr(S<=0), we write:
```{r}
pbinom(n/2-1, size = n, prob = 10/19)
```



## 14.4 Distributions versus probability distributions

1. distribution function
2. drawing from urn with number
3. Monte - Carloe
#1. list of number? > 2,3
#2. 1 is theorical and 3 don't involve urn


## 14.5 Notation for random varibles

X(미래의 예측, random variable) < x(실제 측정값)


## 14.6 The expected value and standard error

E[X] : expected value of random value X
expected value : ap + b(1-p)/ ab는 결과, p와 1-p는 각 결과의 probability

expected value of a random variable defined by one draw is the average of the numbers in the urn

SE[X]: standard error: size of the variation around the expected value.
**(number of draws)^1/2 * standard deviation of the number in the urn**
**standard deviation:|b-a|*(p(1-p))^1/2**


#### 14.6.1 Population SD versus the sample SD
The standard deviation of a list `x` (below we use heights as an example) is defined as the square root of the average of the squared differences:
```{r}
install.packages("dslabs")
library(dslabs)
x <- heights$height
m <- mean(x)
s <- sqrt(mean((x-m)^2))
```
However, be aware that the sd function returns a slightly different result:
```{r}
identical(s, sd(x))
s - sd(x)
```

(x-m)^2의 평균 구할 때 원래대로라면 전체합을 n으로 나눠야되는데 sd(x)는 n-1로 나눔. 그래서 sd(x)대신 정석을 써야되는데 n의 값이 충분히 크면 그게 그거므로 sd(x)써도 됨.


## 14.7 Central Limit Theorem
CLT : number or drawn의 값이 크면 probability distribution of the sum of the independent draws is approximately normal
-> Monte Carlo대신 E[X]와 SE[X]로 값 계산 가능

We previously ran this Monte Carlo simulation:
```{r}
n <- 1000
B <- 10000
roulette_winnings <- function(n){
  X <- sample(c(-1,1), n, replace = TRUE, prob=c(9/19, 10/19))
  sum(X)
}
S <- replicate(B, roulette_winnings(n))
```

The Central Limit Theorem (CLT) tells us that the sum S is approximated by a normal distribution. Using the formulas above, we know that the expected value and standard error are:
```{r}
n * (20-18)/38 
sqrt(n) * 2 * sqrt(90)/19 
```

The theoretical values above match those obtained with the Monte Carlo simulation:
```{r}
mean(S)
sd(S)
```
Using the CLT, we can skip the Monte Carlo simulation and instead compute the probability of the casino losing money using this approximation, which is also in very good agreement with our Monte Carlo result:
```{r}
mu <- n * (20-18)/38
se <-  sqrt(n) * 2 * sqrt(90)/19 
pnorm(0, mu, se)
mean(S < 0)
```


#### 14.7.1 How large is large in the Central Limit THeorem?
보통 30
근데 success의 probability가 매우 낮을때는 아무리 숫자가 커도 normal distribution과 거리가 멈 오히려 **possion distribution**이 더욱 적절

`dpois`, `ppois`, `rpois`


## 14.8 Statistical properties of averages
1. The expected value of the sum of random variables is the sum of each random variable’s expected value.
E[X1 + X2 + X3 ...] = E[X1] + E[X2]..
If the X are independent draws from the urn, then they all have the same expected value. Let’s call it μ and thus:
E[X1 + X2 .. +  Xn] = nμ

2. The expected value of a non-random constant times a random variable is the non-random constant times the expected value of a random variable.
E[aX] = a * E[X]
E[(X1 + X2 .. +  Xn)/n] = E[(X1 + X2 .. +  Xn)]/n = nμ/n = μ

3. SE[X1 + X2 + .. +Xn] = (SE[X1]^2 + ..SE[Xn]^2)^1/2

4. SE[aX] = a*SE[X]

6. X is normally distribiuted random variable
aX + B is normally distributed random variable, that multiplying by a then shifting the center by b.


## 14.9 Law of large numbers
n이 커지면 standard error는 0에 가까워지고 average of draw는 urn의 average에 가까워짐.


#### 14.9.1 Misinterpreting law of average
law of average는 n의 숫자가 클때만 적용되고 각각의 시행은 독립이므로 앞의 결과에 영향을 받지 않는다.


## 14.10 Exercises
1.  In American Roulette you can also bet on green. There are 18 reds, 18 blacks and 2 greens (0 and 00). What are the chances the green comes out?
```{r}
2/(18+18+2)
```

2. The payout for winning on green is $17 dollars. This means that if you bet a dollar and it lands on green, you get $17. Create a sampling model using sample to simulate the random variable X for your winnings. Hint: see the example below for how it should look like when betting on red.
```{r}
X <- sample(c(17, -1), prob = c(2/38,36/38))
```

3. Compute the expected value of X
```{r}
17*2/38 -36/38
```

4. Compute the standard error of X
```{r}
18*sqrt((2/38)*(36/38))
```

5.  Now create a random variable S that is the sum of your winnings after betting on green 1000 times. Hint: change the argument `size` and `replace` in your answer to question 2. Start your code by setting the seed to 1 with `set.seed(1)`.
```{r}
set.seed(1)
sample(c(17, -1), prob = c(2/38,36/38), 1000, replace = TRUE)

set.seed(1)
results <- sample(c(17, -1), prob = c(2/38,36/38), 1000, replace = TRUE)
S <- sum(results)
```

6. What is the expected value of S?
```{r}
1000*((17*2/38)-(36/38))
```

7. What is the standard error of S?
```{r}
sqrt(1000)*18*sqrt((2/38)*(36/38))
```

8. What is the probability that you end up winning money? Hint: use the CLT
```{r}
1 - pnorm(0, -52.63, 127.10)
```

9. Create a Monte Carlo simulation that generates 1,000 outcomes of S. Compute the average and standard deviation of the resulting list to confirm the results of 6 and 7. Start your code by setting the seed to 1 with set.seed(1)
```{r}
B <- 1000
n <- 1000  
set.seed(1)
results <- replicate(B, sum(sample(c(17, -1), n, prob = c(2/38,36/38), replace = TRUE)))
```

10. Now check your answer to 8 using the Monte Carlo result.
```{r}
mean(results>0)
#두 값이 거의 일치한다.
```

11. The Monte Carlo result and the CLT approximation are close, but not that close. What could account for this?

**C. the difference is within rounding error.**

12. Now create a random variable Y that is your average winnings per beet after playing off your winnings after betting on green 1000 times.
```{r}
X <- sample(c(17,-1), 1000, replace=TRUE, prob = c(2/38, 36/38))
Y <- mean(X)
```

13. What is the expected value of Y?
```{r}
1000 * (2/38 * 17 -36/38)
```

14. What is standard error of Y?
```{r}
sqrt(1000)*18*sqrt(2/38*36/38)
```

15. What is the probability that you end up with winning per game that are positive? Hint:use the CLT
```{r}
E <- 1000*(2/38*17-36/38)
SE <- sqrt(1000)*18*sqrt(2/38*36/38)
1-pnorm(0, E, SE)
```

16. Create a Monte Carlo simulation that generate 2500 outcomes of Y. Compute the average and standard deviation of the resulting list.
```{r}
set.seed(1)
n <- 1000
my_function_2 <- function(n){
   Y <- sample(c(17,-1), 1000, replace=TRUE, prob = c(2/38, 36/38))
  mean(Y)
}
result <- replicate(2500, my_function_2(n))
mean(result)
sd(result)
```

17. Now check your answer to 8 using the Monte Carlo result.
```{r}
mean(result > 0)
```

18. The Monte Carlo result and the CLT approximation are now much closer. What could account for this?
**c. The CLT works better when the sample size is larger. WE increased from 1000 to 2500**







## 14.11 Case study: The Big short

#### 14.11.1 Interest rates explained with chance model
More complex versions of the sampling models we have discussed are also used by banks to decide interest rates. Suppose you run a small bank that has a history of identifying potential homeowners that can be trusted to make payments. In fact, historically, in a given year, only 2% of your customers default, meaning that they don’t pay back the money that you lent them. However, you are aware that if you simply loan money to everybody without interest, you will end up losing money due to this 2%. Although you know 2% of your clients will probably default, you don’t know which ones. Yet by charging everybody just a bit extra in interest, you can make up the losses incurred due to that 2% and also cover your operating costs. You can also make a profit, but if you set the interest rates too high, your clients will go to another bank. We use all these facts and some probability theory to decide what interest rate you should charge.

Suppose your bank will give out 1,000 loans for $180,000 this year. Also, after adding up all costs, suppose your bank loses $200,000 per foreclosure. For simplicity, we assume this includes all operational costs. A sampling model for this scenario can be coded like this:
```{r}
n <- 1000
loss_per_foreclosure <- -200000
p <- 0.02 
defaults <- sample( c(0,1), n, prob=c(1-p, p), replace = TRUE)
sum(defaults * loss_per_foreclosure)
```
Note that the total loss defined by the final sum is a random variable. Every time you run the above code, you get a different answer. We can easily construct a Monte Carlo simulation to get an idea of the distribution of this random variable.
```{r}
B <- 10000
losses <- replicate(B, {
    defaults <- sample( c(0,1), n, prob=c(1-p, p), replace = TRUE) 
  sum(defaults * loss_per_foreclosure)
})
```
We don’t really need a Monte Carlo simulation though. Using what we have learned, the CLT tells us that because our losses are a sum of independent draws, its distribution is approximately normal with expected value and standard errors given by:
```{r}
n*(p*loss_per_foreclosure + (1-p)*0)
sqrt(n)*abs(loss_per_foreclosure)*sqrt(p*(1-p))
```

We can now set an interest rate to guarantee that, on average, we break even. Basically, we need to add a quantity  x to each loan, which in this case are represented by draws, so that the expected value is 0. If we define  l to be the loss per foreclosure, we need:
lp + x(1-p) = 0
which implies x is
```{r}
- loss_per_foreclosure*p/(1-p)
```

or an interest rate of 0.023.

However, we still have a problem. Although this interest rate guarantees that on average we break even, there is a 50% chance that we lose money. If our bank loses money, we have to close it down. We therefore need to pick an interest rate that makes it unlikely for this to happen. At the same time, if the interest rate is too high, our clients will go to another bank so we must be willing to take some risks. So let’s say that we want our chances of losing money to be 1 in 100, what does the x quantity need to be now? This one is a bit harder. We want the sum S to have:
Pr(S<0) = 0.01

We know that S is approximately normal. The expected value of S is
E[S] = {lp + x(1-p)}n
with n the number of draws, which is this case represents loans. The standard error is
SD[S] = |x-l|sqrut(np(1-p))

Because x is positive and l negative |x-l| = x-l.  Note that these are just an application of the formulas shown earlier, but using more compact symbols.

Now we are going to use a mathematical “trick” that is very common in statistics. We add and subtract the same quantities to both sides of the event  
S<0 so that the probability does not change and we end up with a standard normal random variable on the left, which will then permit us to write down an equation with only x as an unknown. This “trick” is as follows:

Now because the Z is a normal random with expected value 0 and standard error 1, it means that the quantity on the right side of the < sign must be equal to:
```{r}
qnorm(0.01)
```

The trick works because we end up with an expression containing  x that we know has to be equal to a known quantity  z. Solving for  x is now simply algebra:

which is
```{r}
l <- loss_per_foreclosure
z <- qnorm(0.01)
x <- -l*( n*p - z*sqrt(n*p*(1-p)))/ ( n*(1-p) + z*sqrt(n*p*(1-p)))
x
```

Our interest rate now goes up to 0.035. This is still a very competitive interest rate. By choosing this interest rate, we now have an expected profit per loan of:
```{r}
loss_per_foreclosure*p + x*(1-p)
```

which is a total expected profit of about:
```{r}
n*(loss_per_foreclosure*p + x*(1-p)) 
```
dollars.

We can run a Monte Carlo simulation to double check our theoretical approximations:
```{r}
B <- 100000
profit <- replicate(B, {
    draws <- sample( c(x, loss_per_foreclosure), n, 
                        prob=c(1-p, p), replace = TRUE) 
    sum(draws)
})
mean(profit)
mean(profit<0)
```



#### 14.11.2 The Big Short
One of your employees points out that since the bank is making 2,124 dollars per loan, the bank should give out more loans! Why just n ? You explain that finding those n clients was hard. You need a group that is predictable and that keeps the chances of defaults low. He then points out that even if the probability of default is higher, as long as our expected value is positive, you can minimize your chances of losses by increasing n and relying on the law of large numbers.

He claims that even if the default rate is twice as high, say 4%, if we set the rate just a bit higher than this value:
```{r}
p <- 0.04
r <- (- loss_per_foreclosure*p/(1-p)) / 180000
r
```
we will profit. At 5%, we are guaranteed a positive expected value of:
```{r}
r <- 0.05
x <- r*180000
loss_per_foreclosure*p + x * (1-p)
```
and can minimize our chances of losing money by simply increasing n since:

with Z a standard normal random variable as shown earlier. If we define μ and σ to be the expected value and standard deviation of the urn, respectively (that is of a single loan), using the formulas above we have:  
E[S]=nμ and  SE[S]=√nσ. So if we define z=qnorm(0.01), we have:

we are guaranteed to have a probability of less than 0.01. The implication is that, as long as μ is positive, we can find an n that minimizes the probability of a loss. This is a form of the law of large numbers: when n is large, our average earnings per loan converges to the expected earning μ.

With  x fixed, now we can ask what n do we need for the probability to be 0.01? In our example, if we give out:
```{r}
z <- qnorm(0.01)
n <- ceiling((z^2*(x-l)^2*p*(1-p))/(l*p + x*(1-p))^2)
n
```
loans, the probability of losing is about 0.01 and we are expected to earn a total of
```{r}
n*(loss_per_foreclosure*p + x*(1-p))
```
dollars! We can confirm this with a Monte Carlo simulation:
```{r}
p <- 0.04
x <- 0.05*180000
profit <- replicate(B, {
    draws <- sample( c(x, loss_per_foreclosure), n, 
                        prob=c(1-p, p), replace = TRUE) 
    sum(draws)
})
mean(profit)
```

This seems like a no brainer. As a result, your colleague decides to leave your bank and start his own high-risk mortgage company. A few months later, your colleague’s bank has gone bankrupt. A book is written and eventually a movie is made relating the mistake your friend, and many others, made. What happened?

Your colleague’s scheme was mainly based on this mathematical formula:
SE[(X1 + ...Xn)/n] = σ/√n

By making n large, we minimize the standard error of our per-loan profit. However, for this rule to hold, the  Xs must be independent draws: one person defaulting must be independent of others defaulting. Note that in the case of averaging the same event over and over, an extreme example of events that are not independent, we get a standard error that is  √n times bigger:

SE[(X1 + ...Xn)/n] = SE[nX1/n] = σ > σ/√n

To construct a more realistic simulation than the original one your colleague ran, let’s assume there is a global event that affects everybody with high-risk mortgages and changes their probability. We will assume that with 50-50 chance, all the probabilities go up or down slightly to somewhere between 0.03 and 0.05. But it happens to everybody at once, not just one person. These draws are no longer independent.
```{r}
p <- 0.04
x <- 0.05*180000
profit <- replicate(B, {
    new_p <- 0.04 + sample(seq(-0.01, 0.01, length = 100), 1)
    draws <- sample( c(x, loss_per_foreclosure), n, 
                        prob=c(1-new_p, new_p), replace = TRUE) 
    sum(draws)
})
```

Note that our expected profit is still large:
```{r}
mean(profit)
```

However, the probability of the bank having negative earnings shoots up to:
```{r}
mean(profit<0)
```

Even scarier is that the probability of losing more than 10 million dollars is:
```{r}
mean(profit < -10000000)
```

To understand how this happens look at the distribution:
```{r}
#install.packages("tidyverse")
#library(tidyverse)
data.frame(profit_in_millions=profit/10^6) %>% 
  ggplot(aes(profit_in_millions)) + 
  geom_histogram(color="black", binwidth = 5)
```
The theory completely breaks down and the random variable has much more variability than expected. The financial meltdown of 2007 was due, among other things, to financial “experts” assuming independence when there was none.


## 14.12 Exercises

1. Create a random variable  S with the earnings of your bank if you give out 10,000 loans, the default rate is 0.3, and you lose $200,000 in each foreclosure. Hint: use the code we showed in the previous section, but change the parameters.
```{r}
n <- 10000
loss <- -200000
loan <- sample(c(0,-1), n, prob = c(0.3, 1-0.3), replace = TRUE)
S <- sum(loan * loss)
```
  
2. Run a Monte Carlo simulation with 10000 outcomes for S. Make a histogram of theh results.
```{r}
my_function <- function(n){
X <- sample(c(0,1), n, prob = c(0.3, 1-0.3), replace = TRUE)  
sum(X*loss)}
result <- replicate(10000, my_function(n))
hist(result)
```


3. What is the expected value of s?
```{r}
n*((0.3*loss)+((1-0.3)*0))
```


4. What is the standard error of S?
```{r}
sqrt(n)*(-loss)*sqrt(0.3*(1-0.3))
```


5. Suppose we give out loans for 180000. What should the interest rate be so that our expeected value in 0?
```{r}
x <- -(loss) / (1 - 0.3)
x / 180000
```


6. (Harder) What should the interest rate be so that the chance of losing money is 1 in 20? In math notation, what should the interest rate be so that Pr(S<0) = 0.05?

```{r}
z <- qnorm(0.05)
x <- -loss*( n*0.3 - z*sqrt(n*0.3*(1-0.3)))/ ( n*(1-0.3) + z*sqrt(n*0.3*(1 -0.3)))
x / 180000
```

7. If the bank wants to minimize the probabilites of losing money, which of the following does not make interest rates go up?
**d. The number of Monte Carlo simulations.**