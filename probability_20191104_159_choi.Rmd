---
title: "R Notebook"
output: html_notebook
---
```{r}
install.packages("tidyverse")
library(tidyverse)
```

# Chapter 13 Probability

# 13.1 Discrete probability
discrete porbability: categorial data와 관련




#### 13.1.1 Relative frequency
상대도수: 총 도수에 대한 각 변량의 도수의 비
ex)2R, 3B 공 중 빨간 공 뽑을 확률 = 2/5(모든 경우와 확률 동일)


#### 13.1.2 Notation
Pr(A) <- event A의 porbability


#### 13.1.3 Probability distribution
각 category 별로 relative frequency를 정하는게 일반적 > distribution
ex) category : 한나라, 민주당, 기권
probability distribution = 0.33/0.33/0.34




# 13.2 Monte Carlo simulations for categorical data
**Monte Carlo simuation**: 무한 반복의 결과와 충분히 비슷한 크기만큼 행위반복(make reuslt practically equivalent to repeat infinite)

**`rep`: 반복데이터**
beads <- rep(c=("red","blue"), times = c(2,3))

**`sample`: 무작위로 샘플 추출**
arg: data(frame)-모집단, n-뽑을횟수, replace - 복원여부(T:복원, F: 비복원&dafault)

**`replicate`:표현식 n번 반복**
ex)events <- replicate(1000, sample(beads,1))

**`prob.table`:입력값의 propotion**
ex) prob.table(table(events))
#> blur랑 red의 확률 각각 표시



#### 13.2.1 Settin the random seed
시드지정:특정 사건에 대해 시드를 지정하면, 매번 난수를 입력할 때 그 사건이 반복

`set.seed`
ex) set.seed(1)
    sample(x=1:30, size = 5, replace = T)
    > 이 sample값에 대한 시드가 1로 지정되므로       `set.seed(1)`을 입력하면 해당 sample값이       반복
    

# 13.3 Independence
독립시행 : `sample`의 replace arg = T


# 13.4 Conditional probabilities
Conditional porbabilities : 조건부확률
Pr(A|B) > B가 일어났을 때 P(A)
독립시행은 Pr(A|B) =  Pr(A)



# 13.5 Addition and multiplication rules
#### 13.5.1 Multiplication rule
곱셈법칙: Pr(A and B) = Pr(A)*Pr(A|B)

#### 13.5.2 Multiplication rule under independence
독립시행 : Pr(A&B) = P(A)*P(B)

#### 13.5.3 Additional rule
Pr(A or B) = Pr(A) + Pr(B) - Pr(A&B)


# 13.6 Combinations and premutations

We use `paste` to create strings by joining smaller strings. To do this, we take the number and suit of a card and create the card name like this:    
```{r}
number <- "Three"
suit <- "Hearts"
paste(number, suit)
```
`paste` also works on pairs of vectors performing the operation element-wise:
```{r}
paste(letters[1:5], as.character(1:5))
```
The function `expand.grid` gives us all the combinations of entries of two vectors. For example, if you have blue and black pants and white, grey, and plaid shirts, all your combinations are:
```{r}
expand.grid(pants = c("blue", "black"), shirt = c("white", "grey", "plaid"))
```

Here is how we generate a deck of cards:
```{r}
suits <- c("Diamonds", "Clubs", "Hearts", "Spades")
numbers <- c("Ace", "Deuce", "Three", "Four", "Five", "Six", "Seven", 
             "Eight", "Nine", "Ten", "Jack", "Queen", "King")
deck <- expand.grid(number=numbers, suit=suits)
deck <- paste(deck$number, deck$suit)
```
With the deck constructed, we can double check that the probability of a King in the first card is 1/13 by computing the proportion of possible outcomes that satisfy our condition:
```{r}
kings <- paste("King", suits)
mean(deck %in% kings)
#> [1] 0.0769
```

we can use the permutations function from the gtools package. For any list of size `n`, this function computes all the different combinations we can get when we select `r` items. Here are all the ways we can choose two numbers from a list consisting of `1,2,3`:
```{r}
install.packages("gtools")
library(gtools)
permutations(3, 2)
```

Optionally, we can add a vector. If you want to see five random seven digit phone numbers out of all possible phone numbers (without repeats), you can type:
```{r}
all_phone_numbers <- permutations(10, 7, v = 0:9)
n <- nrow(all_phone_numbers)
index <- sample(n, 5)
all_phone_numbers[index,]
```

Instead of using the numbers 1 through 10, the default, it uses what we provided through `v`: the digits 0 through 9.

To compute all possible ways we can choose two cards when the order matters, we type:
```{r}
hands <- permutations(52, 2, v = deck)
```

This is a matrix with two columns and 2652 rows. With a matrix we can get the first and second cards like this:
```{r}
first_card <- hands[,1]
second_card <- hands[,2]
```

Now the cases for which the first hand was a King can be computed like this:
```{r}
kings <- paste("King", suits)
sum(first_card %in% kings)
```

To get the conditional probability, we compute what fraction of these have a King in the second card:
```{r}
sum(first_card%in%kings & second_card%in%kings) / sum(first_card%in%kings)
```

which is exactly 3/51, as we had already deduced. Notice that the code above is equivalent to:
```{r}
mean(first_card%in%kings & second_card%in%kings) / mean(first_card%in%kings)
```


How about if the order doesn’t matter? For example, in Blackjack if you get an Ace and a face card in the first draw, it is called a Natural 21 and you win automatically. If we wanted to compute the probability of this happening, we would enumerate the combinations, not the permutations, since the order does not matter.
```{r}
combinations(3,2)
```


In the second line, the outcome does not include (2,1) because (1,2) already was enumerated. The same applies to (3,1) and (3,2).

So to compute the probability of a Natural 21 in Blackjack, we can do this:
```{r}
aces <- paste("Ace", suits)

facecard <- c("King", "Queen", "Jack", "Ten")
facecard <- expand.grid(number = facecard, suit = suits)
facecard <- paste(facecard$number, facecard$suit)

hands <- combinations(52, 2, v = deck)
mean(hands[,1] %in% aces & hands[,2] %in% facecard)
```

In the last line, we assume the Ace comes first. This is only because we know the way `combination` enumerates possibilities and it will list this case first. But to be safe, we could have written this and produced the same answer:
```{r}
mean((hands[,1] %in% aces & hands[,2] %in% facecard) |
       (hands[,2] %in% aces & hands[,1] %in% facecard))
```



#### 13.6.1 Monte Carlo example
Instead of using `combinations` to deduce the exact probability of a Natural 21, we can use a Monte Carlo to estimate this probability. In this case, we draw two cards over and over and keep track of how many 21s we get. We can use the function sample to draw two cards without replacements:
```{r}
hand <- sample(deck, 2)
hand
```

And then check if one card is an Ace and the other a face card or a 10. Going forward, we include 10 when we say face card. Now we need to check both possibilities:
```{r}
(hands[1] %in% aces & hands[2] %in% facecard) | 
  (hands[2] %in% aces & hands[1] %in% facecard)
```
If we repeat this 10,000 times, we get a very good approximation of the probability of a Natural 21.

Let’s start by writing a function that draws a hand and returns TRUE if we get a 21. The function does not need any arguments because it uses objects defined in the global environment.
```{r}
blackjack <- function(){
   hand <- sample(deck, 2)
  (hand[1] %in% aces & hand[2] %in% facecard) | 
    (hand[2] %in% aces & hand[1] %in% facecard)
}
```

Here we do have to check both possibilities: Ace first or Ace second because we are not using the `combinations` function. The function returns `TRUE` if we get a 21 and `FALSE` otherwise:
```{r}
blackjack()
```
Now we can play this game, say, 10,000 times:
```{r}
B <- 10000
results <- replicate(B, blackjack())
mean(results)
```



# 13.7 Examples
#### 13.7.1 Monty Hall problem
세 문 중에 하나만 당첨이고, 하나 고른 후 비선택 두개중 꽝인 거 하나 사회자가 오픈해준뒤 한번 바꿀 기회를 주고 결과 발표
과연 바꿈의 기회에서 바꾸는 것이 더 당첨확률이 높은가?
```{r}
B <- 10000
monty_hall <- function(strategy){
  doors <- as.character(1:3)
  prize <- sample(c("car", "goat", "goat"))
  prize_door <- doors[prize == "car"]
  my_pick  <- sample(doors, 1)
  show <- sample(doors[!doors %in% c(my_pick, prize_door)],1)
  stick <- my_pick
  stick == prize_door
  switch <- doors[!doors%in%c(my_pick, show)]
  choice <- ifelse(strategy == "stick", stick, switch)
  choice == prize_door
}
stick <- replicate(B, monty_hall("stick"))
mean(stick)
switch <- replicate(B, monty_hall("switch"))
mean(switch)
```
As we write the code, we note that the lines starting with `my_pick` and `show` have no influence on the last logical operation when we stick to our original choice anyway. From this we should realize that the chance is 1 in 3, what we began with. When we switch, the Monte Carlo estimate confirms the 2/3 calculation. This helps us gain some insight by showing that we are removing a door, `show`, that is definitely not a winner from our choices. We also see that unless we get it right when we first pick, you win: 1 - 1/3 = 2/3.



#### 13.7.2 Birthday problem

birthdays can be represented as numbers between 1 and 365, so a sample of 50 birthdays can be obtained like this:
```{r}
n <- 50
bdays <- sample(1:365, n, replace = TRUE)
```
To check if in this particular set of 50 people we have at least two with the same birthday, we can use the function `duplicated`, which returns `TRUE` whenever an element of a vector is a duplicate. Here is an example:
```{r}
duplicated(c(1,2,3,1,4,3,5))
```
The second time 1 and 3 appear, we get a `TRUE`. So to check if two birthdays were the same, we simply use the `any` and `duplicated` functions like this:
```{r}
any(duplicated(bdays))
```
In this case, we see that it did happen. At least two people had the same birthday.

To estimate the probability of a shared birthday in the group, we repeat this experiment by sampling sets of 50 birthdays over and over:
```{r}
B <- 10000
same_birthday <- function(n){
  bdays <- sample(1:365, n, replace=TRUE)
  any(duplicated(bdays))
}
results <- replicate(B, same_birthday(50))
mean(results)
#> [1] 0.969
```

Say we want to use this knowledge to bet with friends about two people having the same birthday in a group of people. When are the chances larger than 50%? Larger than 75%?

Let’s create a look-up table. We can quickly create a function to compute this for any group size:
```{r}
compute_prob <- function(n, B=10000){
  results <- replicate(B, same_birthday(n))
  mean(results)
}
```

Using the function `sapply`, we can perform element-wise operations on any function:
```{r}
n <- seq(1,60)
prob <- sapply(n, compute_prob)
```

We can now make a plot of the estimated probabilities of two people having the same birthday in a group of size  
n:
```{r}
library(tidyverse)
prob <- sapply(n, compute_prob)
qplot(n, prob)
```

Now let’s compute the exact probabilities rather than use Monte Carlo approximations.
```{r}
exact_prob <- function(n){
  prob_unique <- seq(365,365-n+1)/365 
  1 - prod( prob_unique)
}
eprob <- sapply(n, exact_prob)
qplot(n, prob) + geom_line(aes(n, eprob), col = "red")
```

 
# 13.8 Infinity in practice 
One practical approach we will describe here is to check for the stability of the estimate. The following is an example with the birthday problem for a group of 25 people.
```{r}
B <- 10^seq(1, 5, len = 100)
compute_prob <- function(B, n=25){
  same_day <- replicate(B, same_birthday(n))
  mean(same_day)
}
prob <- sapply(B, compute_prob)
qplot(log10(B), prob, geom = "line")
```

In this plot, we can see that the values start to stabilize (that is, they vary less than .01) around 1000. Note that the exact probability, which we know in this case, is 0.569. 
 
 
 
 
# 13.9 Exercises

1. One ball will be drawn at random from a box containing: 3 cyan balls, 5 magenta balls, and 7 yellow balls. What is the probability that the ball will be cyan?
```{r}
3/(3+5+7)
```

2. What is the probability that the ball will not be cyan?
```{r}
1-0.2
```

3. Instead of taking just one draw, consider taking two draws. You take the second draw without returning the first draw to the box. We call this sampling **without** replacement. What is the probability that the first draw is cyan and that the second draw is not cyan?
```{r}
0.2*(1-(2/14))
```

4. Now repeat the experiment, but this time, after taking the first draw and recording the color, return it to the box and shake the box. We call this sampling **with** replacement. What is the probability that the first draw is cyan and that the second draw is not cyan?
```{r}
0.2*0.8
```

5. Two events A and B are independent if Pr(A and B) = Pr(A)*P(B). Under which situation are the draws independent?

**b. You replace the draw.**

6.  Say you’ve drawn 5 balls from the box, with replacement, and all have been yellow. What is the probability that the next one is yellow?
```{r}
#독립사건이다
7/(3+5+7)
```

7. . If you roll a 6-sided die six times, what is the probability of not seeing a 6?
```{r}
(5/6)^6
```


8.  Two teams, say the Celtics and the Cavs, are playing a seven game series. The Cavs are a better team and have a 60% chance of winning each game. What is the probability that the Celtics win **at least** one game?
```{r}
1-(0.6)^7
```

9. Create a Monte Carlo simulation to confirm your answer to the previous problem. Use `B <- 10000` simulations. Hint: use the following code to generate the results of the first four games:
```{r}
celtic_wins <- sample(c(0,1), 4, replace = TRUE, prob = c(0.6, 0.4))
```
The Celtics must win one of these 4 games.

```{r echo=TRUE}
B <- 10000
my_function <- function(n){
  celtic_wins <- sample(c(0,1), n, replace = TRUE, prob = c(0.6, 0.4)) 
  sum(celtic_wins)
}
results <- replicate(B, my_function(7))
mean(results > 0)
```
**8의 값과 거의 비슷하다**


10. Two teams, say the Cavs and the Warriors, are playing a seven game championship series. The first to win four games, therefore, wins the series. The teams are equally good so they each have a 50-50 chance of winning each game. If the Cavs lose the first game, what is the probability that they win the series?
```{r}
a <- 1/2
1 - (a^3 + (a^4)*3 + (a^5)*6 + (a^6)*10)
```

11. Confirm the results of the previous question with a Monte Carlo simulation.
```{r echo=TRUE}
my_function2 <- function(n){
  Cavs_win <- sample(c(0,1), n, replace = TRUE, prob = c(0.5, 0.5))
  sum(Cavs_win)
}
results <- replicate(B, my_function2(6))
mean(results >= 4)                    
```


12. Two teams, A and B, are playing a seven game series. Team A is better than team B and has a p > 0.5 chance of winning each game. Give a value p the probability of winning the series for the underdog team B can be computed with the following function based on a Monte Carlo simulation:
```{r echo=TRUE}
prob_win <- function(p){
  B <- 10000
  result <- replicate(B, {
    b_win <- sample(c(1,0), 7, replace = TRUE, prob = c(1-p, p))
    sum(b_win)>=4
  })
  mean(result)
}
```
Use the function `sapply` to compute the probability, call it `Pr`, of winning for `p <- seq(0.5, 0.95, 0.025)`. Then plot the result.
```{r echo=TRUE}
p <- seq(0.5, 0.95, 0.025)
pr <- sapply(p, prob_win)
qplot(x = p, y = pr, data = data.frame(pr))
```

13. Repeat the exercise above, but now keep the probability fixed at `p <- 0.75` and compute the probability for different series lengths: best of 1 game, 3 games, 5 games,… Specifically, `N <- seq(1, 25, 2)`. Hint: use this function:
```{r echo=TRUE}
prob_win <- function(N, p=0.75){
  B <- 10000
  result <- replicate(B, {
    b_win <- sample(c(1,0), N, replace = TRUE, prob = c(1-p, p))
    sum(b_win)>=(N+1)/2
  })
  mean(result)
}

N <- seq(1, 25, 2)
win <- sapply(N, prob_win)
qplot(x = N, y = win, data = data.frame(win))
```

# 13.10 Continous probability
CDF : cumulative distribution function, interval로 계산(not element)

mean:특정값이 a보다 클 확률 = mean(x>a)

Once a CDF is defined, we can use this to compute the probability of any subset. For instance, the probability of a student being between height a and height b is:
```{r}
F(b)-F(a)
```


# 13.11 Theorical continuous distributions
F(a) = pnorm(a,m,s) in normal distribution
F(a) <- Pr(x<a)

#### 13.11.1 Theoritical distribution as approximation
interval : rounded number(사람들이 대략 뭉뚱거리는 수..?)를 포함하는 게 좋음
ex) 보통 키에 대한 조사를 한다고 하자. 170언저리인 사람들은 대략 170으로 자신의 키를 뭉뚱그리는 경향이 있다. 그럼 [169.5, 170.5]로 구간을 정하는 것이 똑똑하지 [170.1, 170.9] 이렇게 정하는 것은 멍청하다.


#### 13.11.2 The probability density
`dnorm` : density
dnorm(x) : 정규분포에서 x값의 높이 <- density
즉, 그래프 함수의 f(x)의 값



# 13.12 Monte Carlo simulations for continuous variables
`rnorm` : produce random number(결과:numeric vector)
rnomr(n=size, m = ave, s = sd)

If, for example, we pick 800 males at random, what is the distribution of the tallest person? How rare is a seven footer in a group of 800 males? The following Monte Carlo simulation helps us answer that question:
```{r}
install.packages("dslabs")
library(tidyverse)
library(dslabs)
data(heights)
x <- heights %>% filter(sex=="Male") %>% pull(height)


n <- length(x)
m <- mean(x)
s <- sd(x)
simulated_heights <- rnorm(n, m, s)
```

```{r}
B <- 10000
tallest <- replicate(B, {
  simulated_data <- rnorm(800, m, s)
  max(simulated_data)
})
```
Having a seven footer is quite rare:
```{r}
mean(tallest >= 7*12)
```






# 13.13 Continuous distributions
`dnorm` : 정규분포그래프에서 x의 높이
`qnorm` : quartile
`pnorm` : probability(pnorm(a) = Pr(x<a))
`rnorm` : Monte Carlo simulations

We can therefore draw a distribution like this:
```{r}
x <- seq(-4, 4, length.out = 100)
qplot(x, f, geom = "line", data = data.frame(x, f = dnorm(x)))
```

# 13.14 Exercises
1. Assume the distribution of female heights is approximated by a normal distribution with a mean of 64 inches and a standard deviation of 3 inches. If we pick a female at random, what is the probability that she is 5 feet or shorter?
```{r echo=TRUE}
pnorm(5*12, 64, 3)
```


2.  Assume the distribution of female heights is approximated by a normal distribution with a mean of 64 inches and a standard deviation of 3 inches. If we pick a female at random, what is the probability that she is 6 feet or taller?
```{r echo=TRUE}
1 - pnorm(6*12, 64, 3)
```


3. Assume the distribution of female heights is approximated by a normal distribution with a mean of 64 inches and a standard deviation of 3 inches. If we pick a female at random, what is the probability that she is between 61 and 67 inches?
```{r echo=TRUE}
pnorm(67, 64, 3) - pnorm(61, 64, 3)
```

4. Repeat the exercise above, but convert everything to centimeters. That is, multiply every height, including the standard deviation, by 2.54. What is the answer now?
```{r echo=TRUE}
pnorm(67*2.54, 64*2.54, 3*2.54) - pnorm(61*2.54, 64*2.54, 3*2.54)
```

5. Notice that the answer to the question does not change when you change units. This makes sense since the answer to the question should not be affected by what units we use. In fact, if you look closely, you notice that 60 and 66 are both 1 SD away from the average. Compute the probability that a randomly picked, normally distributed random variable is within 1 SD from the average.
```{r echo=TRUE}
pnorm(66, 63, 3) - pnorm(60, 63, 3)
```

6. To see the math that explains why the answer to questions 3, 4, and 5 are the same, suppose we have a random variable with average m and standard error s. Suppose we ask the probability of X being smaller or equal to a. Remember that, bey definition, a is (a-m)/s standard deviations s away from the average m. The probability is:
Pr(X <= a)

Now we subtract μ to both sides and then devide both sides by σ :
Pr(X-m/s <= a-m/s)
The quantity on the left is a standard normal random variable. It has an average of 0 and a standard error of 1. We will call it Z:
Pr(Z <= a-m/s)

So, no matter the units, the probability of X<=a is the same as the probabiliy of a standard normal variable being less than (a-m)/s. If `mu` is the average and `sigma` the standard error, which of the following R code would give us the right answer in every situation:
**c. pnorm((a - m)/s, m, s)**


7.Imagine the distribution of male adults is approximately normal with an expected value of 69 and a standard deviation of 3. How tall is the male in the 99th percentile? Hint: use `qnorm`.
```{r echo=TRUE}
qnorm(0.99, 69, 3)
```


8. The distribution of IQ scores is approximately normally distributed. The average is 100 and the standard deviation is 15. Suppose you want to know the distribution of the highest IQ across all graduating classes if 10,000 people are born each in your school district. Run a Monte Carlo simulation with `B=10000` generating 10,000 IQ scores and keeping the highest. Make a histogram.
```{r echo=TRUE}
B <- 1000
results <- replicate(B, {rnorm(10000, 100, 15) %>% max()})

qplot(data = data.frame(results), x= results, geom = "histogram")
```

